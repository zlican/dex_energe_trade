package main

import (
	"encoding/json"
	"flag"
	"fmt"
	"io"
	"os"
	"os/signal"
	"path/filepath"
	"rsi/geckoterminal"
	"rsi/telegram"
	"rsi/utils"
	"strings"
	"sync"
	"syscall"
	"time"
)

// TokenConfig ä»£å¸é…ç½®
type TokenConfig struct {
	Network      string `json:"network"`
	TokenAddress string `json:"token_address"`
	Timeframe    string `json:"timeframe"`
	Aggregate    string `json:"aggregate"`
	Description  string `json:"description"`
	PoolAddress  string // å°†åœ¨åˆå§‹åŒ–æ—¶å¡«å……
}

// Config ç¨‹åºé…ç½®
type Config struct {
	DataDir   string        `json:"data_dir"`
	Interval  int           `json:"interval"`
	Proxy     string        `json:"proxy"`
	RSIPeriod int           `json:"rsi_period"`
	Tokens    []TokenConfig `json:"tokens"`
	BotToken  string        `json:"botToken"`
	ChatID    string        `json:"chatId"`
}

// TokenData ä»£å¸æ•°æ®
type TokenData struct {
	Config      TokenConfig
	LatestData  []geckoterminal.OHLCV // ä¿å­˜æœ€æ–°æ•°æ®
	RSIData     []map[string]interface{}
	LastUpdated time.Time
	FilePath    string
	Mutex       sync.Mutex
}

// å…¨å±€å˜é‡
var (
	wg     sync.WaitGroup
	config *Config
)

func main() {

	// å‘½ä»¤è¡Œå‚æ•°
	configFilePtr := flag.String("config", "config.json", "é…ç½®æ–‡ä»¶è·¯å¾„")
	flag.Parse()

	// è¯»å–é…ç½®æ–‡ä»¶
	var err error
	config, err = loadConfig(*configFilePtr)
	if err != nil {
		fmt.Printf("åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
	if err := os.MkdirAll(config.DataDir, 0755); err != nil {
		fmt.Printf("åˆ›å»ºæ•°æ®ç›®å½•å¤±è´¥: %v\n", err)
		os.Exit(1)
	}

	// åˆå§‹åŒ–ä»£å¸æ•°æ®
	tokenDataMap := make(map[string]*TokenData)
	for _, token := range config.Tokens {
		wg.Add(1)
		go func() {
			defer wg.Done()
			// è·å–äº¤æ˜“æ± åœ°å€
			var poolAddress string
			var err error
			for retries := 0; retries < 3; retries++ {
				poolAddress, err = utils.GetPoolAddress(token.Network, token.TokenAddress, config.Proxy)
				if err == nil {
					break
				}
				time.Sleep(2 * time.Second)
			}
			if err != nil {
				fmt.Printf("è·å–äº¤æ˜“æ± åœ°å€å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: %v\n", err)
				return
			}

			tokenConfig := token
			tokenConfig.PoolAddress = poolAddress

			// åˆ›å»ºå›ºå®šçš„æ–‡ä»¶è·¯å¾„ - ä½¿ç”¨ä»£å¸åœ°å€çš„æœ€åéƒ¨åˆ†ä½œä¸ºæ–‡ä»¶å
			var tokenName string
			if token.Description != "" {
				// ä½¿ç”¨æè¿°ä½œä¸ºæ–‡ä»¶åçš„ä¸€éƒ¨åˆ†
				tokenName = sanitizeFileName(token.Description)
			} else {
				// ä½¿ç”¨åœ°å€çš„æœ€åéƒ¨åˆ†
				tokenName = token.TokenAddress
				if len(tokenName) > 8 {
					tokenName = tokenName[len(tokenName)-8:]
				}
			}

			tokenID := fmt.Sprintf("%s_%s", token.Network, tokenName)
			filePath := filepath.Join(config.DataDir, fmt.Sprintf("%s_%s.csv", tokenID, token.Timeframe))

			tokenDataMap[tokenID] = &TokenData{
				Config:   tokenConfig,
				FilePath: filePath,
			}

			fmt.Printf("æ·»åŠ ä»£å¸: %s (%s) - äº¤æ˜“æ± : %s\n",
				token.Description, token.TokenAddress, poolAddress)
		}()
	}
	wg.Wait()

	if len(tokenDataMap) == 0 {
		fmt.Println("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ä»£å¸é…ç½®ï¼Œç¨‹åºé€€å‡º")
		os.Exit(1)
	}

	// è®¾ç½®å®šæ—¶å™¨
	ticker := time.NewTicker(time.Duration(config.Interval) * time.Second)
	defer ticker.Stop()

	// åˆ›å»ºä¸€ä¸ªç»“æŸä¿¡å·é€šé“
	done := make(chan os.Signal, 1)
	signal.Notify(done, syscall.SIGINT, syscall.SIGTERM)

	fmt.Printf("RSIç›‘æ§ç¨‹åºå·²å¯åŠ¨ï¼Œç›‘æ§ %d ä¸ªä»£å¸ï¼Œæ¯ %d ç§’æ›´æ–°ä¸€æ¬¡ï¼ŒæŒ‰Ctrl+Cé€€å‡º...\n",
		len(tokenDataMap), config.Interval)

	// ç«‹å³æ‰§è¡Œä¸€æ¬¡æ›´æ–°
	for id, data := range tokenDataMap {
		updateTokenData(id, data, config.Proxy, config.RSIPeriod)
	}

	// å¾ªç¯æ‰§è¡Œ
	for {
		select {
		case <-done:
			fmt.Println("æ¥æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œç¨‹åºé€€å‡º...")
			return
		case <-ticker.C:
			// å¯¹æ¯ä¸ªä»£å¸æ›´æ–°æ•°æ®
			for id, data := range tokenDataMap {
				go updateTokenData(id, data, config.Proxy, config.RSIPeriod)
			}
		}
	}
}

// loadConfig ä»æ–‡ä»¶åŠ è½½é…ç½®
func loadConfig(filePath string) (*Config, error) {
	file, err := os.Open(filePath)
	if err != nil {
		return nil, fmt.Errorf("æ‰“å¼€é…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}
	defer file.Close()

	data, err := io.ReadAll(file)
	if err != nil {
		return nil, fmt.Errorf("è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	var config Config
	if err := json.Unmarshal(data, &config); err != nil {
		return nil, fmt.Errorf("è§£æé…ç½®æ–‡ä»¶å¤±è´¥: %v", err)
	}

	// è®¾ç½®é»˜è®¤å€¼
	if config.DataDir == "" {
		config.DataDir = "data"
	}
	if config.Interval <= 0 {
		config.Interval = 60
	}
	if config.RSIPeriod <= 0 {
		config.RSIPeriod = 14
	}

	return &config, nil
}

// sanitizeFileName æ¸…ç†æ–‡ä»¶å
func sanitizeFileName(name string) string {
	// æ›¿æ¢ä¸å…è®¸åœ¨æ–‡ä»¶åä¸­ä½¿ç”¨çš„å­—ç¬¦
	invalid := []rune{'<', '>', ':', '"', '/', '\\', '|', '?', '*'}
	for _, r := range invalid {
		name = strings.ReplaceAll(name, string(r), "_")
	}
	return name
}

// updateTokenData æ›´æ–°ä»£å¸æ•°æ®
func updateTokenData(id string, data *TokenData, proxyURL string, rsiPeriod int) {
	data.Mutex.Lock()
	defer data.Mutex.Unlock()

	tokenConfig := data.Config

	// æ„å»ºæŸ¥è¯¢å‚æ•°
	options := map[string]string{
		"aggregate":               tokenConfig.Aggregate,
		"limit":                   "20", // åªè·å–æœ€æ–°çš„å‡ æ¡æ•°æ®å³å¯
		"token":                   "base",
		"currency":                "usd",
		"include_empty_intervals": "true",
	}

	// 1.è·å–OHLCVæ•°æ®
	var ohlcvData []geckoterminal.OHLCV
	var meta *geckoterminal.MetaData
	var err error

	// å¾ªç¯å°è¯•è·å–æ•°æ®ï¼Œç›´åˆ°æˆåŠŸæˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
	maxRetries := 3
	for i := 0; i < maxRetries; i++ {
		ohlcvData, meta, err = geckoterminal.GetOHLCV(tokenConfig.Network, tokenConfig.PoolAddress, tokenConfig.Timeframe, options, proxyURL)
		if err == nil {
			// è·å–æˆåŠŸï¼Œé€€å‡ºå¾ªç¯
			break
		}
		time.Sleep(2 * time.Second) // ç­‰å¾…2ç§’åé‡è¯•
	}

	// å¦‚æœæœ€ç»ˆä»ç„¶å¤±è´¥
	if err != nil {
		fmt.Printf("[%s] å¤šæ¬¡å°è¯•åè·å–OHLCVæ•°æ®å¤±è´¥: %v\n", id, err)
		return
	}

	if len(ohlcvData) == 0 {
		fmt.Printf("[%s] æœªæ‰¾åˆ°OHLCVæ•°æ®\n", id)
		return
	}

	// æ˜¾ç¤ºä»£å¸ä¿¡æ¯
	if meta != nil && data.LastUpdated.IsZero() {
		fmt.Printf("[%s] ä»£å¸ä¿¡æ¯: %s (%s) / %s (%s)\n",
			id,
			meta.Base.Name, meta.Base.Symbol,
			meta.Quote.Name, meta.Quote.Symbol)
	}

	// 2. å»é™¤æœªæ¥æ•°æ®ï¼ˆç¬¬ä¸€ä¸ªé€šå¸¸æ˜¯æœªå®Œæˆçš„æœªæ¥ K çº¿ï¼‰
	if len(ohlcvData) > 0 {
		ohlcvData = ohlcvData[1:]
	}

	// é¦–æ¬¡è¿è¡Œæˆ–å¤ªä¹…æ²¡æ›´æ–°ï¼Œé‡æ–°è·å–æ›´å¤šå†å²æ•°æ®
	var newData []geckoterminal.OHLCV
	if len(data.LatestData) == 0 || time.Since(data.LastUpdated) > 10*time.Minute {
		// è·å–æ›´å¤šå†å²æ•°æ®ä»¥è®¡ç®—å‡†ç¡®çš„RSI
		options["limit"] = "300" // è·å–è¶³å¤Ÿå¤šçš„å†å²æ•°æ®
		ohlcvData, _, err = geckoterminal.GetOHLCV(tokenConfig.Network, tokenConfig.PoolAddress, tokenConfig.Timeframe, options, proxyURL)
		if err != nil {
			fmt.Printf("[%s] è·å–å†å²OHLCVæ•°æ®å¤±è´¥: %v\n", id, err)
			return
		}

		// 2. å»é™¤æœªæ¥æ•°æ®ï¼ˆæœ€åä¸€ä¸ªé€šå¸¸æ˜¯æœªå®Œæˆçš„æœªæ¥ K çº¿ï¼‰
		if len(ohlcvData) > 0 {
			ohlcvData = ohlcvData[1:]
		}

		// å…¨éƒ¨æ•°æ®éƒ½æ˜¯æ–°æ•°æ®
		newData = ohlcvData
		data.LatestData = ohlcvData
	} else {
		// åˆå¹¶æ–°æ•°æ®ä¸ç°æœ‰æ•°æ®
		// æ£€æŸ¥æœ€æ–°æ•°æ®æ˜¯å¦å·²ç»åŒ…å«åœ¨ç°æœ‰æ•°æ®ä¸­
		existingTimestamps := make(map[int64]bool)
		for _, candle := range data.LatestData {
			existingTimestamps[candle.Timestamp] = true
		}

		// æ‰¾å‡ºæ–°æ•°æ®
		for i := 0; i < len(ohlcvData); i++ {
			candle := ohlcvData[i]
			if existingTimestamps[candle.Timestamp] {
				newData = ohlcvData[:i]
				break
			}
		}
		// åˆå¹¶å¹¶ä¿ç•™æœ€å¤š300æ¡
		data.LatestData = append(newData, data.LatestData...)
		if len(data.LatestData) > 300 {
			data.LatestData = data.LatestData[:300]
		}

		// ä½¿ç”¨åˆå¹¶åçš„æ•°æ®è®¡ç®—RSI
		ohlcvData = data.LatestData
	}

	// è®¡ç®—RSI
	data.RSIData = geckoterminal.CalculateRSI(ohlcvData, rsiPeriod)

	// æ›´æ–°æ—¶é—´
	data.LastUpdated = time.Now()

	// åˆ›å»ºRSIå€¼çš„æ˜ å°„ï¼Œä»¥æ—¶é—´æˆ³ä¸ºé”®
	rsiMap := make(map[int64]float64)
	for _, rsi := range data.RSIData {
		timestamp := rsi["timestamp"].(int64)
		rsiMap[timestamp] = rsi["value"].(float64)
	}

	// æ·»åŠ CSVæ ‡é¢˜è¡Œï¼Œåªä¿ç•™æ‰€éœ€çš„åˆ—ï¼šæ—¶é—´ã€æ”¶ç›˜ä»·ã€äº¤æ˜“é‡å’ŒRSI
	var csvData strings.Builder
	csvData.WriteString(fmt.Sprintf("æ—¶é—´,æ”¶ç›˜ä»·,äº¤æ˜“é‡,RSI(%d)\n", rsiPeriod))
	for _, candle := range data.LatestData {
		timeStr := geckoterminal.FormatTimestamp(candle.Timestamp)
		rsiVal := ""
		if val, ok := rsiMap[candle.Timestamp]; ok {
			rsiVal = fmt.Sprintf("%.2f", val)
		}
		csvData.WriteString(fmt.Sprintf("%s,%.8f,%.8f,%s\n",
			timeStr, candle.Close, candle.Volume, rsiVal))
	}

	err = os.WriteFile(data.FilePath, []byte(csvData.String()), 0644)
	if err != nil {
		fmt.Printf("[%s] å†™å…¥æ–‡ä»¶å¤±è´¥: %v\n", id, err)
	}

	// è·å–æœ€æ–°çš„RSIå€¼
	if len(data.RSIData) > 0 {
		latestRSI := data.RSIData[len(data.RSIData)-1]
		if latestRSI["value"].(float64) < 30 {
			message := fmt.Sprintf("ğŸš€ğŸš€[%s] æœ€æ–°RSI(%d)å€¼: %.2f (æ—¶é—´: %s)ğŸš€ğŸš€",
				id, rsiPeriod,
				latestRSI["value"].(float64),
				geckoterminal.FormatTimestamp(latestRSI["timestamp"].(int64)))
			telegram.SendMessage(config.BotToken, config.ChatID, message)
		}
	}
}
